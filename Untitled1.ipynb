{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8adfeae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ppo_pfrl/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ppo_pfrl/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3377: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import logging\n",
    "import random\n",
    "import sys\n",
    "from collections import deque\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import gym\n",
    "import pfrl\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch import nn\n",
    "from gym.wrappers import RescaleAction\n",
    "\n",
    "from util.ppo import PPO_KL\n",
    "from util.modules import  ortho_init, BetaPolicyModel\n",
    "from conditioned_trp_env.envs.conditioned_trp_env import FoodClass\n",
    "\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# Seed\n",
    "##########################################################\n",
    "\n",
    "seed = 100\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "def make_env():\n",
    "    env = gym.make(\n",
    "        \"conditioned_trp_env:SmallLowGearAntCTRP-v0\",\n",
    "        max_episode_steps=np.inf,\n",
    "        internal_reset=\"setpoint\",\n",
    "        n_bins=20,\n",
    "        sensor_range=16,\n",
    "        enable_metabolic=True,\n",
    "    )\n",
    "    env = RescaleAction(env, 0, 1)\n",
    "    env = pfrl.wrappers.CastObservationToFloat32(env)\n",
    "    return env\n",
    "\n",
    "env = make_env()\n",
    "\n",
    "obs_space = env.observation_space\n",
    "action_space = env.action_space\n",
    "\n",
    "obs_size = obs_space.low.size\n",
    "action_size = action_space.low.size\n",
    "\n",
    "policy = BetaPolicyModel(obs_size=obs_size,\n",
    "                         action_size=action_size,\n",
    "                         hidden1=256,\n",
    "                         hidden2=64)\n",
    "\n",
    "value_func = torch.nn.Sequential(\n",
    "    nn.Linear(obs_size, 256),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(256, 64),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(64, 1),\n",
    ")\n",
    "\n",
    "model = pfrl.nn.Branched(policy, value_func)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "agent = PPO_KL(\n",
    "    model=model,\n",
    "    optimizer=opt,\n",
    "    gpu=-1,\n",
    ")\n",
    "\n",
    "\n",
    "agent.load(dirname=\"data/result_trp_therm_oct2021/trp-homeostatic_shaped2021-09-30-14-54-11/150000000_finish\")\n",
    "\n",
    "env = make_env()\n",
    "\n",
    "obs = env.reset(initial_internal=(0.3, -0.2),\n",
    "                object_positions={\"blue\": [],\n",
    "                                  \"red\": [(4, 1), (4, 8)]})\n",
    "\n",
    "while True:\n",
    "    action = agent.act(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7511f236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
